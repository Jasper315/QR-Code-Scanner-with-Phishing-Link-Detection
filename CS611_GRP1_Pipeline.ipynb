{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "1d321337-738e-4366-aab8-73b46d310a06",
   "metadata": {},
   "source": [
    "# CS611: Project Pipeline"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "39e98da5-975a-464f-a3de-37947cf3106e",
   "metadata": {},
   "source": [
    "In this notebook we will build an Amazon SageMaker Pipeline to:\n",
    "1. preprocess the URL data file\n",
    "2. train a model using XGBoost, and \n",
    "3. register a machine learning model to Model Registry. \n",
    "4. deploy an endpoint"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c586f494-2b85-4160-b32d-802696ba910a",
   "metadata": {},
   "source": [
    "## Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "daa71781-2eaa-4f66-8942-a782e31f2858",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: sagemaker in /opt/conda/lib/python3.10/site-packages (2.215.0)\n",
      "Requirement already satisfied: attrs<24,>=23.1.0 in /opt/conda/lib/python3.10/site-packages (from sagemaker) (23.2.0)\n",
      "Requirement already satisfied: boto3<2.0,>=1.33.3 in /opt/conda/lib/python3.10/site-packages (from sagemaker) (1.34.84)\n",
      "Requirement already satisfied: cloudpickle==2.2.1 in /opt/conda/lib/python3.10/site-packages (from sagemaker) (2.2.1)\n",
      "Requirement already satisfied: google-pasta in /opt/conda/lib/python3.10/site-packages (from sagemaker) (0.2.0)\n",
      "Requirement already satisfied: numpy<2.0,>=1.9.0 in /opt/conda/lib/python3.10/site-packages (from sagemaker) (1.26.4)\n",
      "Requirement already satisfied: protobuf<5.0,>=3.12 in /opt/conda/lib/python3.10/site-packages (from sagemaker) (4.25.3)\n",
      "Requirement already satisfied: smdebug-rulesconfig==1.0.1 in /opt/conda/lib/python3.10/site-packages (from sagemaker) (1.0.1)\n",
      "Requirement already satisfied: importlib-metadata<7.0,>=1.4.0 in /opt/conda/lib/python3.10/site-packages (from sagemaker) (6.11.0)\n",
      "Requirement already satisfied: packaging>=20.0 in /opt/conda/lib/python3.10/site-packages (from sagemaker) (23.2)\n",
      "Requirement already satisfied: pandas in /opt/conda/lib/python3.10/site-packages (from sagemaker) (2.2.2)\n",
      "Requirement already satisfied: pathos in /opt/conda/lib/python3.10/site-packages (from sagemaker) (0.3.2)\n",
      "Requirement already satisfied: schema in /opt/conda/lib/python3.10/site-packages (from sagemaker) (0.7.5)\n",
      "Requirement already satisfied: PyYAML~=6.0 in /opt/conda/lib/python3.10/site-packages (from sagemaker) (6.0.1)\n",
      "Requirement already satisfied: jsonschema in /opt/conda/lib/python3.10/site-packages (from sagemaker) (4.21.1)\n",
      "Requirement already satisfied: platformdirs in /opt/conda/lib/python3.10/site-packages (from sagemaker) (4.1.0)\n",
      "Requirement already satisfied: tblib<4,>=1.7.0 in /opt/conda/lib/python3.10/site-packages (from sagemaker) (3.0.0)\n",
      "Requirement already satisfied: urllib3<3.0.0,>=1.26.8 in /opt/conda/lib/python3.10/site-packages (from sagemaker) (2.2.1)\n",
      "Requirement already satisfied: requests in /opt/conda/lib/python3.10/site-packages (from sagemaker) (2.31.0)\n",
      "Requirement already satisfied: docker in /opt/conda/lib/python3.10/site-packages (from sagemaker) (6.1.3)\n",
      "Requirement already satisfied: tqdm in /opt/conda/lib/python3.10/site-packages (from sagemaker) (4.66.1)\n",
      "Requirement already satisfied: psutil in /opt/conda/lib/python3.10/site-packages (from sagemaker) (5.9.8)\n",
      "Requirement already satisfied: botocore<1.35.0,>=1.34.84 in /opt/conda/lib/python3.10/site-packages (from boto3<2.0,>=1.33.3->sagemaker) (1.34.84)\n",
      "Requirement already satisfied: jmespath<2.0.0,>=0.7.1 in /opt/conda/lib/python3.10/site-packages (from boto3<2.0,>=1.33.3->sagemaker) (1.0.1)\n",
      "Requirement already satisfied: s3transfer<0.11.0,>=0.10.0 in /opt/conda/lib/python3.10/site-packages (from boto3<2.0,>=1.33.3->sagemaker) (0.10.1)\n",
      "Requirement already satisfied: zipp>=0.5 in /opt/conda/lib/python3.10/site-packages (from importlib-metadata<7.0,>=1.4.0->sagemaker) (3.17.0)\n",
      "Requirement already satisfied: websocket-client>=0.32.0 in /opt/conda/lib/python3.10/site-packages (from docker->sagemaker) (1.7.0)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /opt/conda/lib/python3.10/site-packages (from requests->sagemaker) (3.3.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /opt/conda/lib/python3.10/site-packages (from requests->sagemaker) (3.6)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.10/site-packages (from requests->sagemaker) (2024.2.2)\n",
      "Requirement already satisfied: six in /opt/conda/lib/python3.10/site-packages (from google-pasta->sagemaker) (1.16.0)\n",
      "Requirement already satisfied: jsonschema-specifications>=2023.03.6 in /opt/conda/lib/python3.10/site-packages (from jsonschema->sagemaker) (2023.12.1)\n",
      "Requirement already satisfied: referencing>=0.28.4 in /opt/conda/lib/python3.10/site-packages (from jsonschema->sagemaker) (0.34.0)\n",
      "Requirement already satisfied: rpds-py>=0.7.1 in /opt/conda/lib/python3.10/site-packages (from jsonschema->sagemaker) (0.18.0)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in /opt/conda/lib/python3.10/site-packages (from pandas->sagemaker) (2.9.0)\n",
      "Requirement already satisfied: pytz>=2020.1 in /opt/conda/lib/python3.10/site-packages (from pandas->sagemaker) (2024.1)\n",
      "Requirement already satisfied: tzdata>=2022.7 in /opt/conda/lib/python3.10/site-packages (from pandas->sagemaker) (2024.1)\n",
      "Requirement already satisfied: ppft>=1.7.6.8 in /opt/conda/lib/python3.10/site-packages (from pathos->sagemaker) (1.7.6.8)\n",
      "Requirement already satisfied: dill>=0.3.8 in /opt/conda/lib/python3.10/site-packages (from pathos->sagemaker) (0.3.8)\n",
      "Requirement already satisfied: pox>=0.3.4 in /opt/conda/lib/python3.10/site-packages (from pathos->sagemaker) (0.3.4)\n",
      "Requirement already satisfied: multiprocess>=0.70.16 in /opt/conda/lib/python3.10/site-packages (from pathos->sagemaker) (0.70.16)\n",
      "Requirement already satisfied: contextlib2>=0.5.5 in /opt/conda/lib/python3.10/site-packages (from schema->sagemaker) (21.6.0)\n",
      "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n",
      "\u001b[0mNote: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "%pip install sagemaker"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "cd3f6338-0296-4613-8bd7-987118b0fca9",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sagemaker.config INFO - Not applying SDK defaults from location: /etc/xdg/sagemaker/config.yaml\n",
      "sagemaker.config INFO - Not applying SDK defaults from location: /root/.config/sagemaker/config.yaml\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import time\n",
    "import boto3\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import sagemaker\n",
    "from sagemaker import get_execution_role\n",
    "from sagemaker.workflow.pipeline_context import PipelineSession"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "0b6bb32b-932b-4297-b71d-07d9abedbb0c",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sagemaker-us-east-1-843047345337\n"
     ]
    }
   ],
   "source": [
    "sess = boto3.Session()\n",
    "sm = sess.client(\"sagemaker\")\n",
    "role = get_execution_role()\n",
    "sagemaker_session = sagemaker.Session(boto_session=sess)\n",
    "bucket = sagemaker_session.default_bucket()\n",
    "region = boto3.Session().region_name\n",
    "\n",
    "pipeline_session = PipelineSession()\n",
    "\n",
    "print(bucket)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "f558e06a-4420-4caa-af0a-ed67a47ba2e1",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DATA_PREFIX: GRP1/data/\n",
      "PIPELINE_NAME: GRP1-pipeline\n",
      "MODEL_PACKAGE_GROUP_NAME: GRP1-ModelPackageGroup\n"
     ]
    }
   ],
   "source": [
    "DATASET_FILE = 'raw_url_dataset.csv'\n",
    "\n",
    "GRP_NAME = 'GRP1' # CHANGE THIS TO YOUR FIRST NAME\n",
    "DATA_PREFIX = f'{GRP_NAME}/data/' # S3 prefix to store data\n",
    "MODEL_OUTPUT_S3_PATH = f's3://{bucket}/{GRP_NAME}/model/' # S3 prefix to store the XGBoost training information and model.\n",
    "\n",
    "BASE_JOB_PROCESSING_NAME = f'{GRP_NAME}-processing'  # base_job_name for preprocessing\n",
    "BASE_JOB_TRAINING_NAME = f'{GRP_NAME}-training'  # base_job_name for training\n",
    "BASE_JOB_EVALUATION_NAME = f'{GRP_NAME}-evaluation'  # base_job_name for evaluation\n",
    "\n",
    "PIPELINE_NAME = f'{GRP_NAME}-pipeline'  # SageMaker Pipeline name\n",
    "MODEL_PACKAGE_GROUP_NAME = f'{GRP_NAME}-ModelPackageGroup'  # Model package group name in the Model Registry\n",
    "\n",
    "print(f'DATA_PREFIX: {DATA_PREFIX}')\n",
    "print(f'PIPELINE_NAME: {PIPELINE_NAME}')\n",
    "print(f'MODEL_PACKAGE_GROUP_NAME: {MODEL_PACKAGE_GROUP_NAME}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "815b2e2a-e310-4f03-a6c9-81340cd715fd",
   "metadata": {},
   "source": [
    "Define Pipeline parameters used to parametrize the pipeline:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "e3ad3791-1157-4934-9bd8-c021933d9563",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from sagemaker.workflow.parameters import ParameterInteger, ParameterString, ParameterFloat\n",
    "\n",
    "# raw input data\n",
    "input_data = ParameterString(name='InputData')\n",
    "\n",
    "# status of newly trained model in registry\n",
    "model_approval_status = ParameterString(name='ModelApprovalStatus', \n",
    "                                        default_value='Approved')\n",
    "\n",
    "# processing step parameters\n",
    "processing_instance_type = ParameterString(name='ProcessingInstanceType', \n",
    "                                           default_value='ml.m5.large')\n",
    "processing_instance_count = ParameterInteger(name='ProcessingInstanceCount', \n",
    "                                             default_value=1)\n",
    "\n",
    "# training step parameters\n",
    "training_instance_type = ParameterString(name='TrainingInstanceType', \n",
    "                                         default_value='ml.m5.large')\n",
    "\n",
    "# model performance step parameters\n",
    "auc_threshold = ParameterFloat(name='AUCThreshold', \n",
    "                                         default_value=0.90)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dd4d2537-1cfb-47ca-856f-f54ce97f586b",
   "metadata": {},
   "source": [
    "Upload data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "ecdddb07-2f5c-4383-bcf3-c4f996b18500",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "s3://sagemaker-us-east-1-843047345337/GRP1/data/raw_url_dataset.csv\n"
     ]
    }
   ],
   "source": [
    "raw_s3_path = sagemaker_session.upload_data(DATASET_FILE, key_prefix=DATA_PREFIX)\n",
    "print(raw_s3_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a9c3a361-a288-41a9-854b-342c852381ea",
   "metadata": {},
   "source": [
    "## Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "b032426d-7df6-495f-91b6-d434b72c0453",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "!mkdir -p code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "a8e7f288-ed26-42ad-829e-88e1bcf72468",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting code/preprocess.py\n"
     ]
    }
   ],
   "source": [
    "%%writefile code/preprocess.py\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import os\n",
    "import json\n",
    "import joblib\n",
    "from io import StringIO\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "import tarfile\n",
    "import logging\n",
    "import re\n",
    "\n",
    "try:\n",
    "    from sagemaker_containers.beta.framework import (\n",
    "        content_types,\n",
    "        encoders,\n",
    "        env,\n",
    "        modules,\n",
    "        transformer,\n",
    "        worker,\n",
    "        server,\n",
    "    )\n",
    "except ImportError:\n",
    "    pass\n",
    "\n",
    "# ================================================================================\n",
    "# Helper functions\n",
    "def clean_url(url):\n",
    "    pattern = r\"(?:^https?://)?([^/]+)\"\n",
    "    match = re.match(pattern, url)\n",
    "    if match:\n",
    "        return match.group(1).lower() \n",
    "    else:\n",
    "        raise ValueError(\"Input not a URL.\")\n",
    "\n",
    "def calculate_url_char_prob(url):\n",
    "    char_probabilities = {\n",
    "        'a': 0.08, 'b': 0.018, 'c': 0.08, 'd': 0.028, 'e': 0.088, 'f': 0.012, \n",
    "        'g': 0.032, 'h': 0.023, 'i': 0.063, 'j': 0.007, 'k': 0.013, 'l': 0.04, \n",
    "        'm': 0.068, 'n': 0.057, 'o': 0.11, 'p': 0.022, 'q': 0.002, 'r': 0.07, \n",
    "        's': 0.054, 't': 0.054, 'u': 0.035, 'v': 0.012, 'w': 0.011, 'x': 0.004, \n",
    "        'y': 0.016, 'z': 0.005, '0': 0.001, '1': 0.0001, '2': 0.0001, '3': 0.0001, \n",
    "        '4': 0.0001, '5': 0.0001, '6': 0.0001, '7': 0.0001, '8': 0.0001, '9': 0.0001\n",
    "    }\n",
    "    cleaned_url = clean_url(url)\n",
    "    total_prob = 0.0\n",
    "    for char in cleaned_url:\n",
    "        if char in char_probabilities:\n",
    "            total_prob += char_probabilities[char]\n",
    "    url_length = len(cleaned_url)\n",
    "    url_char_prob = (total_prob / url_length) if (url_length > 0) else 0    \n",
    "    return url_char_prob\n",
    "\n",
    "def count_digit(url):\n",
    "    domain = clean_url(url)\n",
    "    num_digits = sum(c.isdigit() for c in domain)\n",
    "    return num_digits\n",
    "\n",
    "def find_longest_sequence(s, pattern):\n",
    "    sequences = re.findall(pattern, s)\n",
    "    return max(sequences, key=len, default=\"\")\n",
    "\n",
    "def char_continuation_rate(url):\n",
    "    cleaned_url = clean_url(url)\n",
    "    patterns = {\n",
    "        'alphabet': r'[a-zA-Z]+',\n",
    "        'digit': r'\\d+',\n",
    "        'special': r'[^A-Za-z\\d\\s]+'\n",
    "    }    \n",
    "    total_seq_length = sum(len(find_longest_sequence(cleaned_url, pattern)) for pattern in patterns.values())\n",
    "    total_url_length = len(cleaned_url)\n",
    "    return (total_seq_length / total_url_length) if (total_url_length > 0) else 0\n",
    "\n",
    "def extract_url_features(df):\n",
    "    # Check if 'URL' column exists: Minimum requirement for call\n",
    "    if 'URL' not in df.columns:\n",
    "        raise ValueError(\"The dataframe must contain a column named 'URL'.\")\n",
    "\n",
    "    # Create a new dataframe to hold the features\n",
    "    features_df = pd.DataFrame()\n",
    "\n",
    "    # URL Features: Can be expanded on and reran to include new features in the fit\n",
    "    features_df['CharContinuationRate'] = df['URL'].apply(char_continuation_rate)\n",
    "    features_df['URLCharProb'] = df['URL'].apply(calculate_url_char_prob)\n",
    "    features_df['DomainLength'] = df['URL'].apply(lambda url: len(clean_url(url)))\n",
    "    features_df['SubdomainCount'] = df['URL'].apply(lambda url: clean_url(url).count('.')-1)\n",
    "    features_df['NoOfDigitsInURL'] = df['URL'].apply(count_digit)\n",
    "    features_df['IsHTTPS'] = df['URL'].apply(lambda url: 1 if url.lower().startswith(\"https://\") else 0)    \n",
    "    return features_df\n",
    "\n",
    "# ================================================================================\n",
    "RANDOM_STATE = 2024\n",
    "LABEL_COLUMN = 'label'\n",
    "\n",
    "base_dir = \"/opt/ml/processing\"\n",
    "base_output_dir = \"/opt/ml/output/\"\n",
    "\n",
    "logger = logging.getLogger()\n",
    "logger.setLevel(logging.DEBUG)\n",
    "logger.addHandler(logging.StreamHandler())\n",
    "if __name__ == \"__main__\":\n",
    "    \n",
    "    df = pd.read_csv(f\"{base_dir}/input/raw_url_dataset.csv\")\n",
    "    \n",
    "    feature_data = extract_url_features(df)        \n",
    "    FEATURE_COLUMN = list(feature_data.columns)\n",
    "    \n",
    "    label_data = df[LABEL_COLUMN]\n",
    "\n",
    "    x_train, x_temp, y_train, y_temp = train_test_split(feature_data, label_data, test_size=0.20, stratify=label_data, random_state=RANDOM_STATE)\n",
    "    x_val, x_test, y_val, y_test = train_test_split(x_temp, y_temp, test_size=0.50, stratify=y_temp, random_state=RANDOM_STATE)\n",
    "    \n",
    "    scaler = StandardScaler()\n",
    "    scaler.fit(x_train)\n",
    "    x_train = scaler.transform(x_train)\n",
    "    x_val = scaler.transform(x_val)\n",
    "    x_test = scaler.transform(x_test)\n",
    "    \n",
    "    print(f'Test feature: {x_test}')\n",
    "    print(f'The shape of training set: {x_train.shape}')\n",
    "    print(f'The shape of validation set: {x_val.shape}')\n",
    "    print(f'The shape of testing set: {x_test.shape}')\n",
    "\n",
    "    train_dataset = pd.concat([y_train.reset_index(drop=True), pd.DataFrame(x_train)], axis=1)\n",
    "    val_dataset = pd.concat([y_val.reset_index(drop=True), pd.DataFrame(x_val)], axis=1)\n",
    "    test_dataset = pd.concat([y_test.reset_index(drop=True), pd.DataFrame(x_test)], axis=1)\n",
    "\n",
    "    train_dataset.columns = [LABEL_COLUMN] + FEATURE_COLUMN\n",
    "    val_dataset.columns = [LABEL_COLUMN] + FEATURE_COLUMN\n",
    "    test_dataset.columns = [LABEL_COLUMN] + FEATURE_COLUMN\n",
    "\n",
    "    train_dataset.to_csv(f\"{base_dir}/train/train.csv\", header=None, index=False)\n",
    "    val_dataset.to_csv(f\"{base_dir}/validation/validation.csv\", header=None, index=False)\n",
    "    test_dataset.to_csv(f\"{base_dir}/test/test.csv\", header=None, index=False)\n",
    "    \n",
    "    joblib.dump(scaler, \"model.joblib\")\n",
    "    with tarfile.open(f\"{base_dir}/scaler_model/model.tar.gz\", \"w:gz\") as tar_handle:\n",
    "        tar_handle.add(f\"model.joblib\")\n",
    "\n",
    "def input_fn(input_data, content_type):\n",
    "\n",
    "    logger.debug(\"Starting input:\")\n",
    "    if content_type == \"text/csv\":\n",
    "        df = pd.read_csv(StringIO(input_data))\n",
    "        logger.debug(f\"Sample input csv: {df}\")\n",
    "        return df\n",
    "    elif content_type == \"application/json\":\n",
    "        data = json.loads(input_data)\n",
    "        df = pd.DataFrame([data])\n",
    "        logger.debug(f\"Sample input json: {df}\")\n",
    "        return df\n",
    "    else:\n",
    "        raise ValueError(\"{} not supported by script!\".format(content_type))\n",
    "\n",
    "def output_fn(prediction, accept):\n",
    "    try:\n",
    "        return worker.Response(encoders.encode(prediction, \"text/csv\"), mimetype=\"text/csv\")\n",
    "    except:\n",
    "         raise RuntimeException(\"Original accept: {}. Encoder error with text/csv.\".format(accept))\n",
    "        \n",
    "def predict_fn(input_data, model):\n",
    "    logger.debug(f\"Starting: Feature scaling\")\n",
    "    logger.debug(f\"Data into feature extract: {input_data}\")\n",
    "    feature_data = extract_url_features(input_data)\n",
    "    features = model.transform(feature_data)\n",
    "    logger.debug(f\"Sample feature: {features}\")\n",
    "    return features\n",
    "\n",
    "def model_fn(model_dir):\n",
    "    \"\"\"Deserialize fitted StandardScaler model\"\"\"\n",
    "    preprocessor = joblib.load(os.path.join(model_dir, \"model.joblib\"))\n",
    "    return preprocessor\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "2e102c23-a4c2-412f-92dd-1b5e3543232c",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The input argument instance_type of function (sagemaker.image_uris.retrieve) is a pipeline variable (<class 'sagemaker.workflow.parameters.ParameterString'>), which is interpreted in pipeline execution time only. As the function needs to evaluate the argument value in SDK compile time, the default_value of this Parameter object will be used to override it. Please make sure the default_value is valid.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "s3://sagemaker-us-east-1-843047345337/GRP1/code/preprocess.py\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.10/site-packages/sagemaker/workflow/pipeline_context.py:332: UserWarning: Running within a PipelineSession, there will be No Wait, No Logs, and No Job being started.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "from sagemaker.sklearn.processing import SKLearnProcessor\n",
    "from sagemaker.processing import ProcessingInput, ProcessingOutput\n",
    "\n",
    "CODE_PREFIX = f'{GRP_NAME}/code/' # S3 prefix to store code\n",
    "processcode_s3_path = sagemaker_session.upload_data('code/preprocess.py', key_prefix=CODE_PREFIX)\n",
    "print(processcode_s3_path)\n",
    "\n",
    "sklearn_framework_version = \"1.2-1\"\n",
    "processing_dir = f's3://{bucket}/{GRP_NAME}/processing'\n",
    "\n",
    "sklearn_processor = SKLearnProcessor(\n",
    "    framework_version=sklearn_framework_version,\n",
    "    instance_type=processing_instance_type,\n",
    "    instance_count=processing_instance_count,\n",
    "    base_job_name=BASE_JOB_PROCESSING_NAME,\n",
    "    role=role,\n",
    "    sagemaker_session=pipeline_session\n",
    ")\n",
    "\n",
    "processor_args = sklearn_processor.run(\n",
    "    inputs=[\n",
    "        ProcessingInput(source=input_data, destination=\"/opt/ml/processing/input\"),\n",
    "    ],\n",
    "    outputs=[\n",
    "        ProcessingOutput(output_name=\"scaler_model\", source=\"/opt/ml/processing/scaler_model\", destination=f\"{processing_dir}/scaler_model\"),\n",
    "        ProcessingOutput(output_name=\"train\", source=\"/opt/ml/processing/train\", destination=f\"{processing_dir}/train\"),\n",
    "        ProcessingOutput(output_name=\"validation\", source=\"/opt/ml/processing/validation\", destination=f\"{processing_dir}/validation\"),\n",
    "        ProcessingOutput(output_name=\"test\", source=\"/opt/ml/processing/test\", destination=f\"{processing_dir}/test\"),\n",
    "    ],\n",
    "    code=processcode_s3_path,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "75e8fed8-5443-4553-8a61-7af05415cad6",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from sagemaker.processing import ProcessingInput, ProcessingOutput\n",
    "from sagemaker.workflow.steps import ProcessingStep\n",
    "\n",
    "step_process = ProcessingStep(\n",
    "    name=\"PreprocessData\",\n",
    "    step_args=processor_args,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d9448110-068e-4757-b4de-94fc9dc679e7",
   "metadata": {},
   "source": [
    "## Training (XGBoost) + Hyperparameter Tuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "c184ea97-a1c8-4fe2-8868-c41a16cce9b4",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from sagemaker.inputs import TrainingInput\n",
    "from sagemaker.estimator import Estimator\n",
    "from sagemaker.workflow.steps import TrainingStep, TuningStep\n",
    "from sagemaker.tuner import (\n",
    "    ContinuousParameter,\n",
    "    IntegerParameter,\n",
    "    HyperparameterTuner,\n",
    ")\n",
    "\n",
    "RANDOM_STATE = 2024\n",
    "\n",
    "image_uri = sagemaker.image_uris.retrieve(\n",
    "    framework=\"xgboost\",\n",
    "    region=region,\n",
    "    version=\"1.7-1\",\n",
    "    py_version=\"py3\",\n",
    ")\n",
    "\n",
    "xgb_train = Estimator(\n",
    "    image_uri=image_uri,\n",
    "    instance_type=training_instance_type,\n",
    "    instance_count=1,\n",
    "    output_path=MODEL_OUTPUT_S3_PATH,\n",
    "    base_job_name=BASE_JOB_TRAINING_NAME,\n",
    "    sagemaker_session=pipeline_session,\n",
    "    role=role,\n",
    ")\n",
    "\n",
    "xgb_train.set_hyperparameters(\n",
    "    objective=\"binary:logistic\",\n",
    "    num_round=100,\n",
    "    eta=0.2,\n",
    "    gamma=4,\n",
    "    reg_lambda=10,\n",
    "    subsample=0.7,\n",
    "    verbosity=0\n",
    ")\n",
    "\n",
    "hyperparameter_ranges = {\n",
    "    \"min_child_weight\": IntegerParameter(5, 10, scaling_type=\"Logarithmic\"),\n",
    "    \"max_depth\": IntegerParameter(4, 8, scaling_type=\"Logarithmic\"),\n",
    "    \"alpha\": ContinuousParameter(0.01, 10, scaling_type=\"Logarithmic\"),\n",
    "    \"lambda\": ContinuousParameter(0.01, 10, scaling_type=\"Logarithmic\")\n",
    "}\n",
    "\n",
    "objective_metric_name=\"validation:auc\"\n",
    "tuner_log = HyperparameterTuner(\n",
    "    xgb_train,\n",
    "    objective_metric_name,\n",
    "    hyperparameter_ranges,\n",
    "    max_jobs=3,\n",
    "    max_parallel_jobs=3,\n",
    "    strategy=\"Random\",\n",
    "    objective_type=\"Maximize\",\n",
    "    random_seed=RANDOM_STATE\n",
    ")\n",
    "\n",
    "hpo_args = tuner_log.fit(\n",
    "    inputs={\n",
    "        \"train\": TrainingInput(\n",
    "            s3_data=step_process.properties.ProcessingOutputConfig.Outputs[\"train\"].S3Output.S3Uri,\n",
    "            content_type=\"text/csv\",\n",
    "        ),\n",
    "        \"validation\": TrainingInput(\n",
    "            s3_data=step_process.properties.ProcessingOutputConfig.Outputs[\"validation\"].S3Output.S3Uri,\n",
    "            content_type=\"text/csv\",\n",
    "        ),\n",
    "    }\n",
    ")\n",
    "\n",
    "\n",
    "step_train = TuningStep(\n",
    "    name=\"TrainHPTuning\",\n",
    "    step_args=hpo_args,\n",
    ")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4beda09d-94c9-4016-8942-9fab539eabd5",
   "metadata": {},
   "source": [
    "## Evaluate model [Best model post tuning]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "1573f84b-cbb6-43a2-8c39-e93cba4f392b",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting code/evaluate.py\n"
     ]
    }
   ],
   "source": [
    "%%writefile code/evaluate.py\n",
    "\n",
    "import json\n",
    "import logging\n",
    "import math\n",
    "import pickle\n",
    "import tarfile\n",
    "import os\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import xgboost\n",
    "from sklearn.metrics import mean_squared_error, roc_auc_score, f1_score\n",
    "import pathlib\n",
    "\n",
    "logger = logging.getLogger()\n",
    "logger.setLevel(logging.DEBUG)\n",
    "logger.addHandler(logging.StreamHandler())\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    ## Your code to perform model evaluation on testing dataset, and \n",
    "    ## store the evaluation report\n",
    "    logger.debug(\"Starting evaluation.\")\n",
    "    model_path = \"/opt/ml/processing/model/model.tar.gz\"\n",
    "    with tarfile.open(model_path) as tar:\n",
    "        tar.extractall(path=\".\")\n",
    "\n",
    "    logger.debug(\"Loading xgboost model.\")\n",
    "    model = xgboost.Booster()\n",
    "    model.load_model(\"xgboost-model\")\n",
    "    \n",
    "    logger.debug(\"Reading test data.\")\n",
    "    test_path = \"/opt/ml/processing/test/test.csv\"\n",
    "    df = pd.read_csv(test_path, header=None)\n",
    "    y_test = df.iloc[:, 0].to_numpy()\n",
    "    df.drop(df.columns[0], axis=1, inplace=True)\n",
    "    X_test = xgboost.DMatrix(df.values)\n",
    "\n",
    "    logger.info(\"Performing predictions against test data.\")\n",
    "    predictions = model.predict(X_test)\n",
    "    predictions = np.array(predictions, dtype=float) \n",
    "    binary_predictions = np.where(predictions > 0.5, 1, 0)\n",
    "    \n",
    "    logger.debug(\"Calculating AUC.\")\n",
    "    auc = roc_auc_score(y_test, predictions)\n",
    "    f1_score = f1_score(y_test, binary_predictions)\n",
    "    report_dict = {\n",
    "        \"xgb_metrics\": {\n",
    "            \"AUC\": {\"value\": auc}, \n",
    "            \"f1_score\": {\"value\": f1_score} \n",
    "        },\n",
    "    }\n",
    "\n",
    "    output_dir = \"/opt/ml/processing/evaluation\"\n",
    "    pathlib.Path(output_dir).mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "    logger.info(\"Writing out evaluation report with AUC: %f\", auc)\n",
    "    evaluation_path = f\"{output_dir}/evaluation.json\"\n",
    "    with open(evaluation_path, \"w\") as f:\n",
    "        f.write(json.dumps(report_dict))    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "3a1e9cc8-e297-4be1-b79e-6b4509329eca",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "s3://sagemaker-us-east-1-843047345337/GRP1/code/evaluate.py\n"
     ]
    }
   ],
   "source": [
    "from sagemaker.processing import ScriptProcessor\n",
    "from sagemaker.workflow.properties import PropertyFile\n",
    "\n",
    "MODEL_PREFIX = f'{GRP_NAME}/model'\n",
    "evalout_s3_path = f\"s3://{bucket}/{GRP_NAME}/evaluation\"\n",
    "evalcode_s3_path = sagemaker_session.upload_data('code/evaluate.py', key_prefix=CODE_PREFIX)\n",
    "print(evalcode_s3_path)\n",
    "\n",
    "script_eval = ScriptProcessor(\n",
    "    image_uri=image_uri,\n",
    "    command=[\"python3\"],\n",
    "    instance_type=\"ml.m5.xlarge\",\n",
    "    instance_count=1,\n",
    "    base_job_name=BASE_JOB_EVALUATION_NAME,\n",
    "    sagemaker_session=pipeline_session,\n",
    "    role=role,\n",
    ")\n",
    "\n",
    "evaluation_report = PropertyFile(\n",
    "    name=\"EvaluationReport\",\n",
    "    output_name=\"evaluation\",\n",
    "    path=\"evaluation.json\",\n",
    ")\n",
    "\n",
    "eval_args = script_eval.run(\n",
    "    inputs=[\n",
    "        ProcessingInput(\n",
    "            source=step_train.get_top_model_s3_uri(\n",
    "                top_k=0, \n",
    "                s3_bucket=bucket, \n",
    "                prefix=MODEL_PREFIX\n",
    "            ),\n",
    "            destination=\"/opt/ml/processing/model\",\n",
    "        ),\n",
    "        ProcessingInput(\n",
    "            source=step_process.properties.ProcessingOutputConfig.Outputs[\"test\"].S3Output.S3Uri,\n",
    "            destination=\"/opt/ml/processing/test\",\n",
    "        ),\n",
    "    ],\n",
    "    outputs=[\n",
    "        ProcessingOutput(\n",
    "            output_name=\"evaluation\",\n",
    "            source=\"/opt/ml/processing/evaluation\",\n",
    "            destination=evalout_s3_path\n",
    "        ),\n",
    "    ],\n",
    "    code=evalcode_s3_path,\n",
    ")\n",
    "\n",
    "step_eval = ProcessingStep(\n",
    "    name=\"EvaluateModel\",\n",
    "    step_args=eval_args,\n",
    "    property_files=[evaluation_report],\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8e754e8b-9d88-413f-9929-3900464e7627",
   "metadata": {},
   "source": [
    "## Model package creation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "d12a84b0-bf79-429d-a76d-d012c3a80e2c",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:sagemaker.workflow.utilities:Popping out 'ProcessingJobName' from the pipeline definition by default since it will be overridden at pipeline execution time. Please utilize the PipelineDefinitionConfig to persist this field in the pipeline definition if desired.\n",
      "INFO:sagemaker.image_uris:Ignoring unnecessary instance type: ml.m5.xlarge.\n"
     ]
    }
   ],
   "source": [
    "from sagemaker.xgboost import XGBoostPredictor\n",
    "from sagemaker.model import Model\n",
    "from sagemaker.sklearn.model import SKLearnModel\n",
    "from sagemaker import PipelineModel\n",
    "\n",
    "# Register model to model registry\n",
    "# Combine processing and training for model deployment?\n",
    "scaler_model_s3 = \"{}/model.tar.gz\".format(\n",
    "    step_process.arguments[\"ProcessingOutputConfig\"][\"Outputs\"][0][\"S3Output\"][\"S3Uri\"]\n",
    ")\n",
    "\n",
    "scaler_model = SKLearnModel(\n",
    "    model_data=scaler_model_s3,\n",
    "    role=role,\n",
    "    sagemaker_session=pipeline_session,\n",
    "    entry_point=\"code/preprocess.py\",\n",
    "    framework_version=sklearn_framework_version,\n",
    "    code_location = MODEL_OUTPUT_S3_PATH    \n",
    ")\n",
    "\n",
    "# Define the image URI for XGBoost\n",
    "inference_image_uri = sagemaker.image_uris.retrieve(\n",
    "    framework=\"xgboost\",\n",
    "    region=region,\n",
    "    version=\"1.7-1\",  # Specify the appropriate version for XGBoost\n",
    "    image_scope=\"inference\",\n",
    "    instance_type=\"ml.m5.xlarge\",\n",
    ")\n",
    "\n",
    "xgb_model = Model(\n",
    "    image_uri=inference_image_uri,\n",
    "    model_data=step_train.get_top_model_s3_uri(\n",
    "        top_k=0, \n",
    "        s3_bucket=bucket, \n",
    "        prefix=MODEL_PREFIX\n",
    "    ),\n",
    "    predictor_cls=XGBoostPredictor,\n",
    "    sagemaker_session=pipeline_session,\n",
    "    role=role,\n",
    ")\n",
    "\n",
    "# 2 containers in this model running in a sequential manner\n",
    "pipeline_model = PipelineModel(\n",
    "    models=[scaler_model, xgb_model], \n",
    "    role=role, \n",
    "    sagemaker_session=pipeline_session\n",
    ")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a5746bca-feee-4334-8ed5-4710d8747c9b",
   "metadata": {},
   "source": [
    "## Register Model + Condition step"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "ec5f7be7-f491-4770-a33a-1b192d42c810",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:sagemaker.workflow.utilities:Popping out 'ProcessingJobName' from the pipeline definition by default since it will be overridden at pipeline execution time. Please utilize the PipelineDefinitionConfig to persist this field in the pipeline definition if desired.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "s3://sagemaker-us-east-1-843047345337/GRP1/evaluation/evaluation.json\n"
     ]
    }
   ],
   "source": [
    "from sagemaker.workflow.model_step import ModelStep\n",
    "from sagemaker.model_metrics import MetricsSource, ModelMetrics\n",
    "from sagemaker.workflow.step_collections import RegisterModel\n",
    "from sagemaker.workflow.conditions import ConditionLessThanOrEqualTo\n",
    "from sagemaker.workflow.condition_step import ConditionStep\n",
    "from sagemaker.workflow.functions import JsonGet\n",
    "\n",
    "evaluation_s3_uri = \"{}/evaluation.json\".format(\n",
    "    step_eval.arguments[\"ProcessingOutputConfig\"][\"Outputs\"][0][\"S3Output\"][\"S3Uri\"]\n",
    ")\n",
    "print(evaluation_s3_uri)\n",
    "\n",
    "model_metrics = ModelMetrics(\n",
    "    model_statistics=MetricsSource(\n",
    "        s3_uri=evaluation_s3_uri,\n",
    "        content_type=\"application/json\",\n",
    "    )\n",
    ")\n",
    "\n",
    "register_args = pipeline_model.register(\n",
    "    content_types=[\"text/csv\"],\n",
    "    response_types=[\"text/csv\"],\n",
    "    inference_instances=[\"ml.m5.large\", \"ml.m5.xlarge\"],\n",
    "    transform_instances=[\"ml.m5.xlarge\"],\n",
    "    model_package_group_name=MODEL_PACKAGE_GROUP_NAME,\n",
    "    model_metrics=model_metrics,\n",
    "    approval_status=model_approval_status,\n",
    ")\n",
    "\n",
    "# Make this available in model registry\n",
    "step_register_pipeline_model = ModelStep(\n",
    "    name=PIPELINE_NAME,\n",
    "    step_args=register_args,\n",
    ")\n",
    "\n",
    "cond_lte = ConditionLessThanOrEqualTo(\n",
    "    right=JsonGet(\n",
    "        step_name=step_eval.name,\n",
    "        property_file=evaluation_report,\n",
    "        json_path=\"xgb_metrics.AUC.value\",\n",
    "    ),\n",
    "    left=auc_threshold,\n",
    ")\n",
    "\n",
    "step_cond = ConditionStep(\n",
    "    name=\"CheckAUC-Evaluation\",\n",
    "    conditions=[cond_lte],\n",
    "    if_steps=[step_register_pipeline_model],\n",
    "    else_steps=[],\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "41604c6d-0f66-4898-88d0-a057bc80c958",
   "metadata": {},
   "source": [
    "## SageMaker pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "fb207100-43b9-4503-b327-98db6412ad1e",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from sagemaker.workflow.pipeline import Pipeline\n",
    "from sagemaker.workflow.pipeline_definition_config import PipelineDefinitionConfig\n",
    "\n",
    "pipeline_config = PipelineDefinitionConfig(use_custom_job_prefix=True)\n",
    "\n",
    "# Create a Sagemaker Pipeline.\n",
    "pipeline = Pipeline(\n",
    "    name=PIPELINE_NAME,\n",
    "    parameters=[\n",
    "        training_instance_type,\n",
    "        processing_instance_type,\n",
    "        processing_instance_count,\n",
    "        input_data,\n",
    "        model_approval_status,\n",
    "        auc_threshold,\n",
    "    ],\n",
    "    steps=[step_process, step_train, step_eval, step_cond],\n",
    "    pipeline_definition_config=pipeline_config\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "f5a48d5d-66a4-4349-8aca-19d55608352b",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:sagemaker.estimator:No finished training job found associated with this estimator. Please make sure this estimator is only used for building workflow config\n",
      "WARNING:sagemaker.estimator:No finished training job found associated with this estimator. Please make sure this estimator is only used for building workflow config\n",
      "WARNING:sagemaker.workflow._utils:Popping out 'CertifyForMarketplace' from the pipeline definition since it will be overridden in pipeline execution time.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'Version': '2020-12-01',\n",
       " 'Metadata': {},\n",
       " 'Parameters': [{'Name': 'TrainingInstanceType',\n",
       "   'Type': 'String',\n",
       "   'DefaultValue': 'ml.m5.large'},\n",
       "  {'Name': 'ProcessingInstanceType',\n",
       "   'Type': 'String',\n",
       "   'DefaultValue': 'ml.m5.large'},\n",
       "  {'Name': 'ProcessingInstanceCount', 'Type': 'Integer', 'DefaultValue': 1},\n",
       "  {'Name': 'InputData', 'Type': 'String'},\n",
       "  {'Name': 'ModelApprovalStatus',\n",
       "   'Type': 'String',\n",
       "   'DefaultValue': 'Approved'},\n",
       "  {'Name': 'AUCThreshold', 'Type': 'Float', 'DefaultValue': 0.9}],\n",
       " 'PipelineExperimentConfig': {'ExperimentName': {'Get': 'Execution.PipelineName'},\n",
       "  'TrialName': {'Get': 'Execution.PipelineExecutionId'}},\n",
       " 'Steps': [{'Name': 'PreprocessData',\n",
       "   'Type': 'Processing',\n",
       "   'Arguments': {'ProcessingJobName': 'GRP1-processing',\n",
       "    'ProcessingResources': {'ClusterConfig': {'InstanceType': {'Get': 'Parameters.ProcessingInstanceType'},\n",
       "      'InstanceCount': {'Get': 'Parameters.ProcessingInstanceCount'},\n",
       "      'VolumeSizeInGB': 30}},\n",
       "    'AppSpecification': {'ImageUri': '683313688378.dkr.ecr.us-east-1.amazonaws.com/sagemaker-scikit-learn:1.2-1-cpu-py3',\n",
       "     'ContainerEntrypoint': ['python3',\n",
       "      '/opt/ml/processing/input/code/preprocess.py']},\n",
       "    'RoleArn': 'arn:aws:iam::843047345337:role/LabRole',\n",
       "    'ProcessingInputs': [{'InputName': 'input-1',\n",
       "      'AppManaged': False,\n",
       "      'S3Input': {'S3Uri': {'Get': 'Parameters.InputData'},\n",
       "       'LocalPath': '/opt/ml/processing/input',\n",
       "       'S3DataType': 'S3Prefix',\n",
       "       'S3InputMode': 'File',\n",
       "       'S3DataDistributionType': 'FullyReplicated',\n",
       "       'S3CompressionType': 'None'}},\n",
       "     {'InputName': 'code',\n",
       "      'AppManaged': False,\n",
       "      'S3Input': {'S3Uri': 's3://sagemaker-us-east-1-843047345337/GRP1/code/preprocess.py',\n",
       "       'LocalPath': '/opt/ml/processing/input/code',\n",
       "       'S3DataType': 'S3Prefix',\n",
       "       'S3InputMode': 'File',\n",
       "       'S3DataDistributionType': 'FullyReplicated',\n",
       "       'S3CompressionType': 'None'}}],\n",
       "    'ProcessingOutputConfig': {'Outputs': [{'OutputName': 'scaler_model',\n",
       "       'AppManaged': False,\n",
       "       'S3Output': {'S3Uri': 's3://sagemaker-us-east-1-843047345337/GRP1/processing/scaler_model',\n",
       "        'LocalPath': '/opt/ml/processing/scaler_model',\n",
       "        'S3UploadMode': 'EndOfJob'}},\n",
       "      {'OutputName': 'train',\n",
       "       'AppManaged': False,\n",
       "       'S3Output': {'S3Uri': 's3://sagemaker-us-east-1-843047345337/GRP1/processing/train',\n",
       "        'LocalPath': '/opt/ml/processing/train',\n",
       "        'S3UploadMode': 'EndOfJob'}},\n",
       "      {'OutputName': 'validation',\n",
       "       'AppManaged': False,\n",
       "       'S3Output': {'S3Uri': 's3://sagemaker-us-east-1-843047345337/GRP1/processing/validation',\n",
       "        'LocalPath': '/opt/ml/processing/validation',\n",
       "        'S3UploadMode': 'EndOfJob'}},\n",
       "      {'OutputName': 'test',\n",
       "       'AppManaged': False,\n",
       "       'S3Output': {'S3Uri': 's3://sagemaker-us-east-1-843047345337/GRP1/processing/test',\n",
       "        'LocalPath': '/opt/ml/processing/test',\n",
       "        'S3UploadMode': 'EndOfJob'}}]}}},\n",
       "  {'Name': 'TrainHPTuning',\n",
       "   'Type': 'Tuning',\n",
       "   'Arguments': {'HyperParameterTuningJobName': 'sagemaker-xgboost',\n",
       "    'HyperParameterTuningJobConfig': {'Strategy': 'Random',\n",
       "     'ResourceLimits': {'MaxNumberOfTrainingJobs': 3,\n",
       "      'MaxParallelTrainingJobs': 3},\n",
       "     'TrainingJobEarlyStoppingType': 'Off',\n",
       "     'RandomSeed': 2024,\n",
       "     'HyperParameterTuningJobObjective': {'Type': 'Maximize',\n",
       "      'MetricName': 'validation:auc'},\n",
       "     'ParameterRanges': {'ContinuousParameterRanges': [{'Name': 'alpha',\n",
       "        'MinValue': '0.01',\n",
       "        'MaxValue': '10',\n",
       "        'ScalingType': 'Logarithmic'},\n",
       "       {'Name': 'lambda',\n",
       "        'MinValue': '0.01',\n",
       "        'MaxValue': '10',\n",
       "        'ScalingType': 'Logarithmic'}],\n",
       "      'CategoricalParameterRanges': [],\n",
       "      'IntegerParameterRanges': [{'Name': 'min_child_weight',\n",
       "        'MinValue': '5',\n",
       "        'MaxValue': '10',\n",
       "        'ScalingType': 'Logarithmic'},\n",
       "       {'Name': 'max_depth',\n",
       "        'MinValue': '4',\n",
       "        'MaxValue': '8',\n",
       "        'ScalingType': 'Logarithmic'}]}},\n",
       "    'TrainingJobDefinition': {'StaticHyperParameters': {'objective': 'binary:logistic',\n",
       "      'num_round': '100',\n",
       "      'eta': '0.2',\n",
       "      'gamma': '4',\n",
       "      'reg_lambda': '10',\n",
       "      'subsample': '0.7',\n",
       "      'verbosity': '0'},\n",
       "     'RoleArn': 'arn:aws:iam::843047345337:role/LabRole',\n",
       "     'OutputDataConfig': {'S3OutputPath': 's3://sagemaker-us-east-1-843047345337/GRP1/model/'},\n",
       "     'StoppingCondition': {'MaxRuntimeInSeconds': 86400},\n",
       "     'HyperParameterTuningResourceConfig': {'InstanceCount': 1,\n",
       "      'InstanceType': {'Get': 'Parameters.TrainingInstanceType'},\n",
       "      'VolumeSizeInGB': 30},\n",
       "     'AlgorithmSpecification': {'TrainingInputMode': 'File',\n",
       "      'TrainingImage': '683313688378.dkr.ecr.us-east-1.amazonaws.com/sagemaker-xgboost:1.7-1'},\n",
       "     'InputDataConfig': [{'DataSource': {'S3DataSource': {'S3DataType': 'S3Prefix',\n",
       "         'S3Uri': {'Get': \"Steps.PreprocessData.ProcessingOutputConfig.Outputs['train'].S3Output.S3Uri\"},\n",
       "         'S3DataDistributionType': 'FullyReplicated'}},\n",
       "       'ContentType': 'text/csv',\n",
       "       'ChannelName': 'train'},\n",
       "      {'DataSource': {'S3DataSource': {'S3DataType': 'S3Prefix',\n",
       "         'S3Uri': {'Get': \"Steps.PreprocessData.ProcessingOutputConfig.Outputs['validation'].S3Output.S3Uri\"},\n",
       "         'S3DataDistributionType': 'FullyReplicated'}},\n",
       "       'ContentType': 'text/csv',\n",
       "       'ChannelName': 'validation'}]}}},\n",
       "  {'Name': 'EvaluateModel',\n",
       "   'Type': 'Processing',\n",
       "   'Arguments': {'ProcessingJobName': 'GRP1-evaluation',\n",
       "    'ProcessingResources': {'ClusterConfig': {'InstanceType': 'ml.m5.xlarge',\n",
       "      'InstanceCount': 1,\n",
       "      'VolumeSizeInGB': 30}},\n",
       "    'AppSpecification': {'ImageUri': '683313688378.dkr.ecr.us-east-1.amazonaws.com/sagemaker-xgboost:1.7-1',\n",
       "     'ContainerEntrypoint': ['python3',\n",
       "      '/opt/ml/processing/input/code/evaluate.py']},\n",
       "    'RoleArn': 'arn:aws:iam::843047345337:role/LabRole',\n",
       "    'ProcessingInputs': [{'InputName': 'input-1',\n",
       "      'AppManaged': False,\n",
       "      'S3Input': {'S3Uri': {'Std:Join': {'On': '/',\n",
       "         'Values': ['s3:/',\n",
       "          'sagemaker-us-east-1-843047345337',\n",
       "          'GRP1/model',\n",
       "          {'Get': 'Steps.TrainHPTuning.TrainingJobSummaries[0].TrainingJobName'},\n",
       "          'output/model.tar.gz']}},\n",
       "       'LocalPath': '/opt/ml/processing/model',\n",
       "       'S3DataType': 'S3Prefix',\n",
       "       'S3InputMode': 'File',\n",
       "       'S3DataDistributionType': 'FullyReplicated',\n",
       "       'S3CompressionType': 'None'}},\n",
       "     {'InputName': 'input-2',\n",
       "      'AppManaged': False,\n",
       "      'S3Input': {'S3Uri': {'Get': \"Steps.PreprocessData.ProcessingOutputConfig.Outputs['test'].S3Output.S3Uri\"},\n",
       "       'LocalPath': '/opt/ml/processing/test',\n",
       "       'S3DataType': 'S3Prefix',\n",
       "       'S3InputMode': 'File',\n",
       "       'S3DataDistributionType': 'FullyReplicated',\n",
       "       'S3CompressionType': 'None'}},\n",
       "     {'InputName': 'code',\n",
       "      'AppManaged': False,\n",
       "      'S3Input': {'S3Uri': 's3://sagemaker-us-east-1-843047345337/GRP1/code/evaluate.py',\n",
       "       'LocalPath': '/opt/ml/processing/input/code',\n",
       "       'S3DataType': 'S3Prefix',\n",
       "       'S3InputMode': 'File',\n",
       "       'S3DataDistributionType': 'FullyReplicated',\n",
       "       'S3CompressionType': 'None'}}],\n",
       "    'ProcessingOutputConfig': {'Outputs': [{'OutputName': 'evaluation',\n",
       "       'AppManaged': False,\n",
       "       'S3Output': {'S3Uri': 's3://sagemaker-us-east-1-843047345337/GRP1/evaluation',\n",
       "        'LocalPath': '/opt/ml/processing/evaluation',\n",
       "        'S3UploadMode': 'EndOfJob'}}]}},\n",
       "   'PropertyFiles': [{'PropertyFileName': 'EvaluationReport',\n",
       "     'OutputName': 'evaluation',\n",
       "     'FilePath': 'evaluation.json'}]},\n",
       "  {'Name': 'CheckAUC-Evaluation',\n",
       "   'Type': 'Condition',\n",
       "   'Arguments': {'Conditions': [{'Type': 'LessThanOrEqualTo',\n",
       "      'LeftValue': {'Get': 'Parameters.AUCThreshold'},\n",
       "      'RightValue': {'Std:JsonGet': {'PropertyFile': {'Get': 'Steps.EvaluateModel.PropertyFiles.EvaluationReport'},\n",
       "        'Path': 'xgb_metrics.AUC.value'}}}],\n",
       "    'IfSteps': [{'Name': 'GRP1-pipeline-RegisterModel',\n",
       "      'Type': 'RegisterModel',\n",
       "      'Arguments': {'ModelPackageGroupName': 'GRP1-ModelPackageGroup',\n",
       "       'ModelMetrics': {'ModelQuality': {'Statistics': {'ContentType': 'application/json',\n",
       "          'S3Uri': 's3://sagemaker-us-east-1-843047345337/GRP1/evaluation/evaluation.json'}},\n",
       "        'Bias': {},\n",
       "        'Explainability': {}},\n",
       "       'InferenceSpecification': {'Containers': [{'Image': '683313688378.dkr.ecr.us-east-1.amazonaws.com/sagemaker-scikit-learn:1.2-1-cpu-py3',\n",
       "          'Environment': {'SAGEMAKER_PROGRAM': 'preprocess.py',\n",
       "           'SAGEMAKER_SUBMIT_DIRECTORY': 's3://sagemaker-us-east-1-843047345337/GRP1/model/sagemaker-scikit-learn-2024-07-01-04-07-55-170/sourcedir.tar.gz',\n",
       "           'SAGEMAKER_CONTAINER_LOG_LEVEL': '20',\n",
       "           'SAGEMAKER_REGION': 'us-east-1'},\n",
       "          'ModelDataUrl': 's3://sagemaker-us-east-1-843047345337/GRP1/processing/scaler_model/model.tar.gz'},\n",
       "         {'Image': '683313688378.dkr.ecr.us-east-1.amazonaws.com/sagemaker-xgboost:1.7-1',\n",
       "          'Environment': {},\n",
       "          'ModelDataUrl': {'Std:Join': {'On': '/',\n",
       "            'Values': ['s3:/',\n",
       "             'sagemaker-us-east-1-843047345337',\n",
       "             'GRP1/model',\n",
       "             {'Get': 'Steps.TrainHPTuning.TrainingJobSummaries[0].TrainingJobName'},\n",
       "             'output/model.tar.gz']}}}],\n",
       "        'SupportedContentTypes': ['text/csv'],\n",
       "        'SupportedResponseMIMETypes': ['text/csv'],\n",
       "        'SupportedRealtimeInferenceInstanceTypes': ['ml.m5.large',\n",
       "         'ml.m5.xlarge'],\n",
       "        'SupportedTransformInstanceTypes': ['ml.m5.xlarge']},\n",
       "       'ModelApprovalStatus': {'Get': 'Parameters.ModelApprovalStatus'},\n",
       "       'SkipModelValidation': 'None'}}],\n",
       "    'ElseSteps': []}}]}"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import json\n",
    "\n",
    "# JSON definition is a representation of the graph (workflow), submit in sagemaker pipeline\n",
    "definition = json.loads(pipeline.definition())\n",
    "definition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "d870354d-2c58-44a9-beed-cfd102eaee35",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:sagemaker.estimator:No finished training job found associated with this estimator. Please make sure this estimator is only used for building workflow config\n",
      "WARNING:sagemaker.estimator:No finished training job found associated with this estimator. Please make sure this estimator is only used for building workflow config\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'PipelineArn': 'arn:aws:sagemaker:us-east-1:843047345337:pipeline/GRP1-pipeline',\n",
       " 'ResponseMetadata': {'RequestId': 'f34087a3-f9aa-4745-9d26-ce075a63963d',\n",
       "  'HTTPStatusCode': 200,\n",
       "  'HTTPHeaders': {'x-amzn-requestid': 'f34087a3-f9aa-4745-9d26-ce075a63963d',\n",
       "   'content-type': 'application/x-amz-json-1.1',\n",
       "   'content-length': '81',\n",
       "   'date': 'Mon, 01 Jul 2024 04:07:56 GMT'},\n",
       "  'RetryAttempts': 0}}"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pipeline.upsert(role_arn=role)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "1ae6ea66-9d8e-46c5-a32e-80bfc4593ae9",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "execution = pipeline.start(\n",
    "    parameters=dict(\n",
    "        InputData=raw_s3_path\n",
    "    )\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "b6511b9b-32b0-420d-8736-675346ef93a8",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'StepName': 'GRP1-pipeline-RegisterModel',\n",
       "  'StartTime': datetime.datetime(2024, 7, 1, 4, 19, 4, 297000, tzinfo=tzlocal()),\n",
       "  'EndTime': datetime.datetime(2024, 7, 1, 4, 19, 5, 627000, tzinfo=tzlocal()),\n",
       "  'StepStatus': 'Succeeded',\n",
       "  'Metadata': {'RegisterModel': {'Arn': 'arn:aws:sagemaker:us-east-1:843047345337:model-package/GRP1-ModelPackageGroup/1'}},\n",
       "  'AttemptCount': 1},\n",
       " {'StepName': 'CheckAUC-Evaluation',\n",
       "  'StartTime': datetime.datetime(2024, 7, 1, 4, 19, 3, 325000, tzinfo=tzlocal()),\n",
       "  'EndTime': datetime.datetime(2024, 7, 1, 4, 19, 3, 596000, tzinfo=tzlocal()),\n",
       "  'StepStatus': 'Succeeded',\n",
       "  'Metadata': {'Condition': {'Outcome': 'True'}},\n",
       "  'AttemptCount': 1},\n",
       " {'StepName': 'EvaluateModel',\n",
       "  'StartTime': datetime.datetime(2024, 7, 1, 4, 16, 29, 413000, tzinfo=tzlocal()),\n",
       "  'EndTime': datetime.datetime(2024, 7, 1, 4, 19, 2, 456000, tzinfo=tzlocal()),\n",
       "  'StepStatus': 'Succeeded',\n",
       "  'Metadata': {'ProcessingJob': {'Arn': 'arn:aws:sagemaker:us-east-1:843047345337:processing-job/GRP1-evaluation-d1e4au3toxag-hSnwwOJkmb'}},\n",
       "  'AttemptCount': 1},\n",
       " {'StepName': 'TrainHPTuning',\n",
       "  'StartTime': datetime.datetime(2024, 7, 1, 4, 13, 1, 39000, tzinfo=tzlocal()),\n",
       "  'EndTime': datetime.datetime(2024, 7, 1, 4, 16, 28, 586000, tzinfo=tzlocal()),\n",
       "  'StepStatus': 'Succeeded',\n",
       "  'Metadata': {'TuningJob': {'Arn': 'arn:aws:sagemaker:us-east-1:843047345337:hyper-parameter-tuning-job/sagemake-d1e4au3toxag-cIBohrIaPw'}},\n",
       "  'AttemptCount': 1},\n",
       " {'StepName': 'PreprocessData',\n",
       "  'StartTime': datetime.datetime(2024, 7, 1, 4, 7, 57, 489000, tzinfo=tzlocal()),\n",
       "  'EndTime': datetime.datetime(2024, 7, 1, 4, 13, 0, 349000, tzinfo=tzlocal()),\n",
       "  'StepStatus': 'Succeeded',\n",
       "  'Metadata': {'ProcessingJob': {'Arn': 'arn:aws:sagemaker:us-east-1:843047345337:processing-job/GRP1-processing-d1e4au3toxag-ahWTPGvuVc'}},\n",
       "  'AttemptCount': 1}]"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "execution.wait()\n",
    "execution.list_steps()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "00e0ec7d-665f-4d8b-aa64-39fe1e65fc83",
   "metadata": {},
   "source": [
    "## Endpoint deployment + Testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "e93c01e4-9e50-44af-b317-be956429ae4f",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Endpoint Name= GRP1-endpoint-2024-07-01-04-19-28\n"
     ]
    }
   ],
   "source": [
    "ENDPOINT_NAME = f'{GRP_NAME}-endpoint-' + time.strftime('%Y-%m-%d-%H-%M-%S', time.gmtime())\n",
    "print(f'Endpoint Name= {ENDPOINT_NAME}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "b1bcae0b-f3ed-4760-9e52-0e34683994e7",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from botocore.exceptions import ClientError\n",
    "\n",
    "def get_approved_package(model_package_group_name):\n",
    "    \"\"\"Gets the latest approved model package for a model package group.\n",
    "\n",
    "    Args:\n",
    "        model_package_group_name: The model package group name.\n",
    "\n",
    "    Returns:\n",
    "        The SageMaker Model Package ARN.\n",
    "    \"\"\"\n",
    "    try:\n",
    "        # Get the latest approved model package\n",
    "        response = sm_client.list_model_packages(\n",
    "            ModelPackageGroupName=model_package_group_name,\n",
    "            ModelApprovalStatus=\"Approved\",\n",
    "            SortBy=\"CreationTime\",\n",
    "            MaxResults=100,\n",
    "        )\n",
    "        approved_packages = response[\"ModelPackageSummaryList\"]\n",
    "\n",
    "        # Fetch more packages if none returned with continuation token\n",
    "        while len(approved_packages) == 0 and \"NextToken\" in response:\n",
    "            response = sm_client.list_model_packages(\n",
    "                ModelPackageGroupName=model_package_group_name,\n",
    "                ModelApprovalStatus=\"Approved\",\n",
    "                SortBy=\"CreationTime\",\n",
    "                MaxResults=100,\n",
    "                NextToken=response[\"NextToken\"],\n",
    "            )\n",
    "            approved_packages.extend(response[\"ModelPackageSummaryList\"])\n",
    "\n",
    "        # Return error if no packages found\n",
    "        if len(approved_packages) == 0:\n",
    "            error_message = (\n",
    "                f\"No approved ModelPackage found for ModelPackageGroup: {model_package_group_name}\"\n",
    "            )\n",
    "            raise Exception(error_message)\n",
    "\n",
    "        # Return the pmodel package arn\n",
    "        model_package_arn = approved_packages[0][\"ModelPackageArn\"]\n",
    "        return approved_packages[0]\n",
    "        # return model_package_arn\n",
    "    except ClientError as e:\n",
    "        error_message = e.response[\"Error\"][\"Message\"]\n",
    "        raise Exception(error_message)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "02761624-bd2f-4239-86ae-cde1c8c0d739",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'ModelPackageGroupName': 'GRP1-ModelPackageGroup',\n",
       " 'ModelPackageVersion': 1,\n",
       " 'ModelPackageArn': 'arn:aws:sagemaker:us-east-1:843047345337:model-package/GRP1-ModelPackageGroup/1',\n",
       " 'CreationTime': datetime.datetime(2024, 7, 1, 4, 19, 5, 485000, tzinfo=tzlocal()),\n",
       " 'InferenceSpecification': {'Containers': [{'Image': '683313688378.dkr.ecr.us-east-1.amazonaws.com/sagemaker-scikit-learn:1.2-1-cpu-py3',\n",
       "    'ImageDigest': 'sha256:ed242e33af079f334972acd2a7ddf74d13310d3c9a0ef3a0e9b0429ccc104dcd',\n",
       "    'ModelDataUrl': 's3://sagemaker-us-east-1-843047345337/GRP1/processing/scaler_model/model.tar.gz',\n",
       "    'Environment': {'SAGEMAKER_CONTAINER_LOG_LEVEL': '20',\n",
       "     'SAGEMAKER_PROGRAM': 'preprocess.py',\n",
       "     'SAGEMAKER_REGION': 'us-east-1',\n",
       "     'SAGEMAKER_SUBMIT_DIRECTORY': 's3://sagemaker-us-east-1-843047345337/GRP1/model/sagemaker-scikit-learn-2024-07-01-04-07-55-170/sourcedir.tar.gz'}},\n",
       "   {'Image': '683313688378.dkr.ecr.us-east-1.amazonaws.com/sagemaker-xgboost:1.7-1',\n",
       "    'ImageDigest': 'sha256:9aaafe236a367412ead0e5cd4704789ed2f4901e6a98f61e861ed61853748720',\n",
       "    'ModelDataUrl': 's3://sagemaker-us-east-1-843047345337/GRP1/model/sagemake-d1e4au3toxag-cIBohrIaPw-003-e79c62e0/output/model.tar.gz',\n",
       "    'Environment': {}}],\n",
       "  'SupportedTransformInstanceTypes': ['ml.m5.xlarge'],\n",
       "  'SupportedRealtimeInferenceInstanceTypes': ['ml.m5.large', 'ml.m5.xlarge'],\n",
       "  'SupportedContentTypes': ['text/csv'],\n",
       "  'SupportedResponseMIMETypes': ['text/csv']},\n",
       " 'ModelPackageStatus': 'Completed',\n",
       " 'ModelPackageStatusDetails': {'ValidationStatuses': [],\n",
       "  'ImageScanStatuses': []},\n",
       " 'CertifyForMarketplace': False,\n",
       " 'ModelApprovalStatus': 'Approved',\n",
       " 'CreatedBy': {'IamIdentity': {'Arn': 'arn:aws:sts::843047345337:assumed-role/LabRole/sagemaker-pipeline-d1e4au3toxag-GRP1-pipeline-Regist',\n",
       "   'PrincipalId': 'AROA4ISMJTS4XCR4U7Y7Z:sagemaker-pipeline-d1e4au3toxag-GRP1-pipeline-Regist'}},\n",
       " 'MetadataProperties': {'GeneratedBy': 'arn:aws:sagemaker:us-east-1:843047345337:pipeline/grp1-pipeline/execution/d1e4au3toxag'},\n",
       " 'ModelMetrics': {'ModelQuality': {'Statistics': {'ContentType': 'application/json',\n",
       "    'S3Uri': 's3://sagemaker-us-east-1-843047345337/GRP1/evaluation/evaluation.json'}},\n",
       "  'Bias': {},\n",
       "  'Explainability': {}},\n",
       " 'SkipModelValidation': 'None',\n",
       " 'ResponseMetadata': {'RequestId': 'd3779feb-8b5f-44ed-b265-b202f66e66f6',\n",
       "  'HTTPStatusCode': 200,\n",
       "  'HTTPHeaders': {'x-amzn-requestid': 'd3779feb-8b5f-44ed-b265-b202f66e66f6',\n",
       "   'content-type': 'application/x-amz-json-1.1',\n",
       "   'content-length': '2061',\n",
       "   'date': 'Mon, 01 Jul 2024 04:19:28 GMT'},\n",
       "  'RetryAttempts': 0}}"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sm_client = boto3.client(\"sagemaker\")\n",
    "\n",
    "pck = get_approved_package(\n",
    "    MODEL_PACKAGE_GROUP_NAME\n",
    ")\n",
    "model_description = sm_client.describe_model_package(ModelPackageName=pck[\"ModelPackageArn\"])\n",
    "\n",
    "model_description"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "669a4e80-3df1-41f2-8dd0-bdd2bf083331",
   "metadata": {},
   "source": [
    "Deploy the model from the Model Registry into an endpoint."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "3bac20c5-e4e7-489b-8f48-59ae7a961afb",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:sagemaker:Creating model with name: GRP1-ModelPackageGroup-2024-07-01-04-19-29-321\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EndpointName= GRP1-endpoint-2024-07-01-04-19-28\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:sagemaker:Creating endpoint-config with name GRP1-endpoint-2024-07-01-04-19-28\n",
      "INFO:sagemaker:Creating endpoint with name GRP1-endpoint-2024-07-01-04-19-28\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------!"
     ]
    }
   ],
   "source": [
    "from sagemaker import ModelPackage\n",
    "\n",
    "model_package_arn = pck[\"ModelPackageArn\"]\n",
    "model = ModelPackage(\n",
    "    role=role, model_package_arn=model_package_arn, sagemaker_session=sagemaker_session\n",
    ")\n",
    "\n",
    "print(\"EndpointName= {}\".format(ENDPOINT_NAME))\n",
    "model.deploy(initial_instance_count=1, instance_type=\"ml.m5.xlarge\", endpoint_name=ENDPOINT_NAME)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "76de5b7f-13db-4d01-9786-20d5a1be9779",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Status: InService\n"
     ]
    }
   ],
   "source": [
    "response = sm_client.describe_endpoint(EndpointName=ENDPOINT_NAME)\n",
    "status = response['EndpointStatus']\n",
    "print(\"Status: \" + status)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "41e40378-90c0-4cab-8fd3-dba67e9aa55a",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "endpoint/GRP1-endpoint-2024-07-01-04-19-28/variant/AllTraffic\n"
     ]
    }
   ],
   "source": [
    "# AutoScaling client\n",
    "asg = boto3.client('application-autoscaling')\n",
    "\n",
    "# Resource type is variant and the unique identifier is the resource ID.\n",
    "EndPoint_id = f'endpoint/{ENDPOINT_NAME}/variant/AllTraffic' # S3 prefix to store model\n",
    "print(EndPoint_id)\n",
    "\n",
    "# scaling configuration\n",
    "response = asg.register_scalable_target(\n",
    "    ServiceNamespace='sagemaker', #\n",
    "    ResourceId=EndPoint_id,\n",
    "    ScalableDimension='sagemaker:variant:DesiredInstanceCount', \n",
    "    MinCapacity=2,\n",
    "    MaxCapacity=4\n",
    ")\n",
    "\n",
    "#Target Scaling\n",
    "response = asg.put_scaling_policy(\n",
    "    PolicyName=f'Request-ScalingPolicy-{ENDPOINT_NAME}',\n",
    "    ServiceNamespace='sagemaker',\n",
    "    ResourceId=EndPoint_id,\n",
    "    ScalableDimension='sagemaker:variant:DesiredInstanceCount',\n",
    "    PolicyType='TargetTrackingScaling',\n",
    "    TargetTrackingScalingPolicyConfiguration={\n",
    "        'TargetValue': 10.0, # Threshold\n",
    "        'PredefinedMetricSpecification': {\n",
    "            'PredefinedMetricType': 'SageMakerVariantInvocationsPerInstance',\n",
    "        },\n",
    "        'ScaleInCooldown': 300, # duration until scale in\n",
    "        'ScaleOutCooldown': 60 # duration between scale out\n",
    "    }\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ded5ba86-ae53-487a-9eb8-30954cf6bd07",
   "metadata": {},
   "source": [
    "After the model is deployed, we use some data points from our raw dataset for testing."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "34c8082c-1ffa-4f19-94a9-9d08f773936b",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9960029721260071\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "\n",
    "smr = boto3.client('sagemaker-runtime')\n",
    "\n",
    "url1 = \"https://www.smu.edu.sg\"\n",
    "url2 = \"https://www.youtube.com/watch?v=jgpRAiar2LQ\"\n",
    "\n",
    "payload = json.dumps({\"URL\": url1})\n",
    "resp = smr.invoke_endpoint(EndpointName=ENDPOINT_NAME, Body=payload, ContentType='application/json')\n",
    "print(resp['Body'].read().decode('utf-8'))\n",
    "                           "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "759e5650-13da-4e46-84a8-96313f741999",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9712852239608765\n",
      "0.00017983945144806057\n",
      "0.9798189401626587\n",
      "0.9846684336662292\n",
      "0.01017708145081997\n",
      "0.025043800473213196\n",
      "0.95907062292099\n",
      "0.0002088078181259334\n",
      "0.980344295501709\n",
      "0.00024241443315986544\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sagemaker.predictor import Predictor\n",
    "\n",
    "predictor = Predictor(endpoint_name=ENDPOINT_NAME)\n",
    "\n",
    "df = pd.read_csv(DATASET_FILE)\n",
    "label_data = df['label']\n",
    "feature_data = df.drop('label', axis=1, inplace=False)\n",
    "\n",
    "start_row = 800\n",
    "pred_count = 10\n",
    "payload = feature_data.iloc[start_row:start_row+pred_count].to_csv(header=True, index=False)\n",
    "p = predictor.predict(payload, initial_args={\"ContentType\": \"text/csv\"})\n",
    "print(p.decode(\"utf-8\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "d705b9d1-65d7-4c4c-9c8c-ec08e21e6c54",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicted: 0.9712852239608765 and Actual is: 1\n",
      "Predicted: 0.00017983945144806057 and Actual is: 0\n",
      "Predicted: 0.9798189401626587 and Actual is: 1\n",
      "Predicted: 0.9846684336662292 and Actual is: 1\n",
      "Predicted: 0.01017708145081997 and Actual is: 0\n",
      "Predicted: 0.025043800473213196 and Actual is: 0\n",
      "Predicted: 0.95907062292099 and Actual is: 1\n",
      "Predicted: 0.0002088078181259334 and Actual is: 0\n",
      "Predicted: 0.980344295501709 and Actual is: 1\n",
      "Predicted: 0.00024241443315986544 and Actual is: 0\n"
     ]
    }
   ],
   "source": [
    "predictions = p.decode(\"utf-8\").split('\\n')\n",
    "for i in range(pred_count):\n",
    "    print(\n",
    "        f\"Predicted: {predictions[i]} and Actual is: {label_data.iloc[start_row+i]}\"\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "f092f172-4418-4a6c-b184-0ccdb81af11f",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Status: Updating\n",
      "Status: Updating\n",
      "Current Instance count: 1\n",
      "Status: Updating\n",
      "Current Instance count: 1\n",
      "Status: Updating\n",
      "Current Instance count: 1\n",
      "Status: Updating\n",
      "Current Instance count: 1\n",
      "Status: Updating\n",
      "Current Instance count: 1\n",
      "Status: Updating\n",
      "Current Instance count: 1\n",
      "Status: Updating\n",
      "Current Instance count: 1\n",
      "Status: Updating\n",
      "Current Instance count: 1\n",
      "Status: Updating\n",
      "Current Instance count: 1\n",
      "Status: Updating\n",
      "Current Instance count: 1\n",
      "Status: Updating\n",
      "Current Instance count: 1\n",
      "Status: Updating\n",
      "Current Instance count: 1\n",
      "Status: Updating\n",
      "Current Instance count: 1\n",
      "Status: Updating\n",
      "Current Instance count: 1\n",
      "Status: Updating\n",
      "Current Instance count: 1\n",
      "Status: Updating\n",
      "Current Instance count: 1\n",
      "Status: Updating\n",
      "Current Instance count: 1\n",
      "Status: Updating\n",
      "Current Instance count: 1\n",
      "Status: Updating\n",
      "Current Instance count: 1\n",
      "Status: Updating\n",
      "Current Instance count: 1\n",
      "Status: Updating\n",
      "Current Instance count: 1\n",
      "Status: Updating\n",
      "Current Instance count: 1\n",
      "Status: Updating\n",
      "Current Instance count: 1\n",
      "Status: Updating\n",
      "Current Instance count: 1\n",
      "Status: Updating\n",
      "Current Instance count: 1\n",
      "Status: Updating\n",
      "Current Instance count: 1\n",
      "Status: Updating\n",
      "Current Instance count: 1\n",
      "Status: Updating\n",
      "Current Instance count: 1\n",
      "Status: Updating\n",
      "Current Instance count: 1\n",
      "Status: Updating\n",
      "Current Instance count: 1\n",
      "Status: Updating\n",
      "Current Instance count: 1\n",
      "Status: Updating\n",
      "Current Instance count: 1\n",
      "Status: Updating\n",
      "Current Instance count: 1\n",
      "Status: Updating\n",
      "Current Instance count: 1\n",
      "Status: Updating\n",
      "Current Instance count: 1\n",
      "Status: Updating\n",
      "Current Instance count: 1\n",
      "Status: Updating\n",
      "Current Instance count: 1\n",
      "Status: Updating\n",
      "Current Instance count: 1\n",
      "Status: Updating\n",
      "Current Instance count: 1\n",
      "Status: Updating\n",
      "Current Instance count: 1\n",
      "Status: Updating\n",
      "Current Instance count: 1\n",
      "Status: Updating\n",
      "Current Instance count: 1\n",
      "Status: Updating\n",
      "Current Instance count: 1\n",
      "Status: Updating\n",
      "Current Instance count: 1\n",
      "Status: Updating\n",
      "Current Instance count: 1\n",
      "Status: Updating\n",
      "Current Instance count: 1\n",
      "Status: Updating\n",
      "Current Instance count: 1\n",
      "Status: Updating\n",
      "Current Instance count: 1\n",
      "Status: Updating\n",
      "Current Instance count: 1\n",
      "Status: Updating\n",
      "Current Instance count: 1\n",
      "Status: Updating\n",
      "Current Instance count: 1\n",
      "Status: Updating\n",
      "Current Instance count: 1\n",
      "Status: Updating\n",
      "Current Instance count: 1\n",
      "Status: Updating\n",
      "Current Instance count: 1\n",
      "Status: Updating\n",
      "Current Instance count: 1\n",
      "Status: Updating\n",
      "Current Instance count: 1\n",
      "Status: Updating\n",
      "Current Instance count: 1\n",
      "Status: Updating\n",
      "Current Instance count: 1\n",
      "Status: Updating\n",
      "Current Instance count: 1\n",
      "Status: Updating\n",
      "Current Instance count: 1\n",
      "Status: Updating\n",
      "Current Instance count: 1\n",
      "Status: Updating\n",
      "Current Instance count: 1\n",
      "Status: Updating\n",
      "Current Instance count: 1\n",
      "Status: Updating\n",
      "Current Instance count: 1\n",
      "Status: Updating\n",
      "Current Instance count: 1\n",
      "Status: Updating\n",
      "Current Instance count: 1\n",
      "Status: Updating\n",
      "Current Instance count: 1\n",
      "Status: Updating\n",
      "Current Instance count: 1\n",
      "Status: Updating\n",
      "Current Instance count: 1\n",
      "Status: Updating\n",
      "Current Instance count: 1\n",
      "Status: Updating\n",
      "Current Instance count: 1\n",
      "Status: Updating\n",
      "Current Instance count: 1\n",
      "Status: Updating\n",
      "Current Instance count: 1\n",
      "Status: Updating\n",
      "Current Instance count: 1\n",
      "Status: Updating\n",
      "Current Instance count: 1\n",
      "Status: Updating\n",
      "Current Instance count: 1\n",
      "Status: Updating\n",
      "Current Instance count: 1\n",
      "Status: Updating\n",
      "Current Instance count: 1\n",
      "Status: Updating\n",
      "Current Instance count: 1\n",
      "Status: Updating\n",
      "Current Instance count: 1\n",
      "Status: Updating\n",
      "Current Instance count: 1\n",
      "Status: Updating\n",
      "Current Instance count: 1\n",
      "Status: Updating\n",
      "Current Instance count: 1\n",
      "Status: Updating\n",
      "Current Instance count: 1\n",
      "Status: Updating\n",
      "Current Instance count: 1\n",
      "Status: Updating\n",
      "Current Instance count: 1\n",
      "Status: Updating\n",
      "Current Instance count: 1\n",
      "Status: Updating\n",
      "Current Instance count: 1\n",
      "Status: Updating\n",
      "Current Instance count: 1\n",
      "Status: Updating\n",
      "Current Instance count: 1\n",
      "Status: Updating\n",
      "Current Instance count: 1\n",
      "Status: Updating\n",
      "Current Instance count: 1\n",
      "Status: Updating\n",
      "Current Instance count: 1\n",
      "Status: Updating\n",
      "Current Instance count: 1\n",
      "Status: Updating\n",
      "Current Instance count: 1\n",
      "Status: Updating\n",
      "Current Instance count: 1\n",
      "Status: Updating\n",
      "Current Instance count: 1\n",
      "Status: Updating\n",
      "Current Instance count: 1\n",
      "Status: Updating\n",
      "Current Instance count: 1\n",
      "Status: Updating\n",
      "Current Instance count: 1\n",
      "Status: Updating\n",
      "Current Instance count: 1\n",
      "Status: Updating\n",
      "Current Instance count: 1\n",
      "Status: Updating\n",
      "Current Instance count: 1\n",
      "Status: Updating\n",
      "Current Instance count: 1\n",
      "Status: Updating\n",
      "Current Instance count: 1\n",
      "Status: Updating\n",
      "Current Instance count: 1\n",
      "Status: Updating\n",
      "Current Instance count: 1\n",
      "Status: Updating\n",
      "Current Instance count: 1\n",
      "Status: Updating\n",
      "Current Instance count: 1\n",
      "Status: Updating\n",
      "Current Instance count: 1\n",
      "Status: Updating\n",
      "Current Instance count: 1\n",
      "Status: Updating\n",
      "Current Instance count: 1\n",
      "Status: Updating\n",
      "Current Instance count: 1\n",
      "Status: Updating\n",
      "Current Instance count: 1\n",
      "Status: Updating\n",
      "Current Instance count: 1\n",
      "Status: Updating\n",
      "Current Instance count: 1\n",
      "Status: Updating\n",
      "Current Instance count: 1\n",
      "Status: Updating\n",
      "Current Instance count: 1\n",
      "Status: Updating\n",
      "Current Instance count: 1\n",
      "Status: Updating\n",
      "Current Instance count: 1\n",
      "Status: Updating\n",
      "Current Instance count: 1\n",
      "Status: Updating\n",
      "Current Instance count: 1\n",
      "Status: Updating\n",
      "Current Instance count: 1\n",
      "Status: Updating\n",
      "Current Instance count: 1\n",
      "Status: Updating\n",
      "Current Instance count: 1\n",
      "Status: Updating\n",
      "Current Instance count: 1\n",
      "Status: Updating\n",
      "Current Instance count: 1\n",
      "Status: Updating\n",
      "Current Instance count: 1\n",
      "Status: Updating\n",
      "Current Instance count: 1\n",
      "Status: Updating\n",
      "Current Instance count: 1\n",
      "Status: Updating\n",
      "Current Instance count: 1\n",
      "Status: Updating\n",
      "Current Instance count: 1\n",
      "Status: Updating\n",
      "Current Instance count: 1\n",
      "Status: Updating\n",
      "Current Instance count: 1\n",
      "Status: Updating\n",
      "Current Instance count: 1\n",
      "Status: Updating\n",
      "Current Instance count: 1\n",
      "Status: Updating\n",
      "Current Instance count: 1\n",
      "Status: Updating\n",
      "Current Instance count: 1\n",
      "Status: Updating\n",
      "Current Instance count: 1\n",
      "Status: Updating\n",
      "Current Instance count: 1\n",
      "Status: Updating\n",
      "Current Instance count: 1\n",
      "Status: Updating\n",
      "Current Instance count: 1\n",
      "Status: Updating\n",
      "Current Instance count: 1\n",
      "Status: Updating\n",
      "Current Instance count: 1\n",
      "Status: Updating\n",
      "Current Instance count: 1\n",
      "Status: Updating\n",
      "Current Instance count: 1\n",
      "Status: Updating\n",
      "Current Instance count: 1\n",
      "Status: Updating\n",
      "Current Instance count: 1\n",
      "Status: Updating\n",
      "Current Instance count: 1\n",
      "Status: Updating\n",
      "Current Instance count: 1\n",
      "Status: Updating\n",
      "Current Instance count: 1\n",
      "Status: Updating\n",
      "Current Instance count: 1\n",
      "Status: Updating\n",
      "Current Instance count: 1\n",
      "Status: Updating\n",
      "Current Instance count: 1\n",
      "Status: Updating\n",
      "Current Instance count: 1\n",
      "Status: Updating\n",
      "Current Instance count: 1\n",
      "Status: Updating\n",
      "Current Instance count: 1\n",
      "Status: Updating\n",
      "Current Instance count: 1\n",
      "Status: Updating\n",
      "Current Instance count: 1\n",
      "Status: Updating\n",
      "Current Instance count: 1\n",
      "Status: Updating\n",
      "Current Instance count: 1\n",
      "Status: Updating\n",
      "Current Instance count: 1\n",
      "Status: Updating\n",
      "Current Instance count: 1\n",
      "Status: Updating\n",
      "Current Instance count: 1\n",
      "Status: Updating\n",
      "Current Instance count: 1\n",
      "Status: Updating\n",
      "Current Instance count: 1\n",
      "Status: Updating\n",
      "Current Instance count: 1\n",
      "Status: Updating\n",
      "Current Instance count: 1\n",
      "Status: Updating\n",
      "Current Instance count: 1\n",
      "Status: Updating\n",
      "Current Instance count: 1\n",
      "Status: Updating\n",
      "Current Instance count: 1\n",
      "Status: Updating\n",
      "Current Instance count: 1\n",
      "Status: Updating\n",
      "Current Instance count: 1\n",
      "Status: Updating\n",
      "Current Instance count: 1\n",
      "Status: Updating\n",
      "Current Instance count: 1\n",
      "Status: Updating\n",
      "Current Instance count: 1\n",
      "Status: Updating\n",
      "Current Instance count: 1\n",
      "Status: Updating\n",
      "Current Instance count: 1\n",
      "Status: Updating\n",
      "Current Instance count: 1\n",
      "Status: Updating\n",
      "Current Instance count: 1\n",
      "Status: Updating\n",
      "Current Instance count: 1\n",
      "Status: Updating\n",
      "Current Instance count: 1\n",
      "Status: Updating\n",
      "Current Instance count: 1\n",
      "Status: Updating\n",
      "Current Instance count: 1\n",
      "Status: Updating\n",
      "Current Instance count: 1\n",
      "Status: Updating\n",
      "Current Instance count: 1\n",
      "Status: Updating\n",
      "Current Instance count: 1\n",
      "Status: Updating\n",
      "Current Instance count: 1\n",
      "Status: Updating\n",
      "Current Instance count: 1\n",
      "Status: Updating\n",
      "Current Instance count: 1\n",
      "Status: Updating\n",
      "Current Instance count: 1\n",
      "Status: Updating\n",
      "Current Instance count: 1\n",
      "Status: Updating\n",
      "Current Instance count: 1\n",
      "Status: Updating\n",
      "Current Instance count: 1\n",
      "Status: Updating\n",
      "Current Instance count: 1\n",
      "Status: Updating\n",
      "Current Instance count: 1\n",
      "Status: Updating\n",
      "Current Instance count: 1\n",
      "Status: Updating\n",
      "Current Instance count: 1\n",
      "Status: Updating\n",
      "Current Instance count: 1\n",
      "Status: Updating\n",
      "Current Instance count: 1\n",
      "Status: Updating\n",
      "Current Instance count: 1\n",
      "Status: Updating\n",
      "Current Instance count: 1\n",
      "Status: Updating\n",
      "Current Instance count: 1\n",
      "Status: Updating\n",
      "Current Instance count: 1\n",
      "Status: Updating\n",
      "Current Instance count: 1\n",
      "Status: Updating\n",
      "Current Instance count: 1\n",
      "Status: Updating\n",
      "Current Instance count: 1\n",
      "Status: Updating\n",
      "Current Instance count: 1\n",
      "Status: Updating\n",
      "Current Instance count: 1\n",
      "Status: Updating\n",
      "Current Instance count: 1\n",
      "Status: Updating\n",
      "Current Instance count: 1\n",
      "Status: Updating\n",
      "Current Instance count: 1\n",
      "Status: Updating\n",
      "Current Instance count: 1\n",
      "Status: Updating\n",
      "Current Instance count: 1\n",
      "Status: Updating\n",
      "Current Instance count: 1\n",
      "Status: Updating\n",
      "Current Instance count: 2\n",
      "Status: Updating\n",
      "Current Instance count: 2\n",
      "Status: Updating\n",
      "Current Instance count: 2\n",
      "Status: Updating\n",
      "Current Instance count: 2\n",
      "Status: Updating\n",
      "Current Instance count: 2\n",
      "Status: Updating\n",
      "Current Instance count: 2\n",
      "Status: Updating\n",
      "Current Instance count: 2\n",
      "Status: Updating\n",
      "Current Instance count: 2\n",
      "Status: InService\n",
      "Current Instance count: 2\n"
     ]
    }
   ],
   "source": [
    "response = sm_client.describe_endpoint(EndpointName=ENDPOINT_NAME)\n",
    "status = response['EndpointStatus']\n",
    "print(\"Status: \" + status)\n",
    "\n",
    "while status=='Updating':\n",
    "    time.sleep(1)\n",
    "    response = sm_client.describe_endpoint(EndpointName=ENDPOINT_NAME)\n",
    "    status = response['EndpointStatus']\n",
    "    instance_count = response['ProductionVariants'][0]['CurrentInstanceCount']\n",
    "    print(f\"Status: {status}\")\n",
    "    print(f\"Current Instance count: {instance_count}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5872e6c4-7032-4596-8341-26add26aae59",
   "metadata": {},
   "source": [
    "## Clean-up\n",
    "- Delete model package\n",
    "- Delete endpoint\n",
    "- Delete pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "34e0d339-f92d-4b2e-9cad-132a6859ce0b",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "arn:aws:sagemaker:us-east-1:843047345337:model-package/GRP1-ModelPackageGroup/1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:sagemaker:Deleting endpoint configuration with name: GRP1-endpoint-2024-07-01-04-19-28\n",
      "INFO:sagemaker:Deleting endpoint with name: GRP1-endpoint-2024-07-01-04-19-28\n",
      "INFO:sagemaker.workflow.pipeline:If triggers have been setup for this target, they will become orphaned.You will need to clean them up manually via the CLI or EventBridge console.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'PipelineArn': 'arn:aws:sagemaker:us-east-1:843047345337:pipeline/GRP1-pipeline',\n",
       " 'ResponseMetadata': {'RequestId': 'c5b80ef3-34a7-475b-a984-d24d4836f0fd',\n",
       "  'HTTPStatusCode': 200,\n",
       "  'HTTPHeaders': {'x-amzn-requestid': 'c5b80ef3-34a7-475b-a984-d24d4836f0fd',\n",
       "   'content-type': 'application/x-amz-json-1.1',\n",
       "   'content-length': '81',\n",
       "   'date': 'Mon, 01 Jul 2024 04:28:14 GMT'},\n",
       "  'RetryAttempts': 0}}"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sm_client = boto3.client(\"sagemaker\")\n",
    "\n",
    "for d in sm_client.list_model_packages(ModelPackageGroupName=MODEL_PACKAGE_GROUP_NAME)[\n",
    "    \"ModelPackageSummaryList\"\n",
    "]:\n",
    "    print(d[\"ModelPackageArn\"])\n",
    "    sm_client.delete_model_package(ModelPackageName=d[\"ModelPackageArn\"])\n",
    "\n",
    "sm_client.delete_model_package_group(ModelPackageGroupName=MODEL_PACKAGE_GROUP_NAME)\n",
    "predictor.delete_endpoint()\n",
    "pipeline.delete()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9e0af5d3-5fcd-47b8-a406-e2ced3a19a90",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "availableInstances": [
   {
    "_defaultOrder": 0,
    "_isFastLaunch": true,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 4,
    "name": "ml.t3.medium",
    "vcpuNum": 2
   },
   {
    "_defaultOrder": 1,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 8,
    "name": "ml.t3.large",
    "vcpuNum": 2
   },
   {
    "_defaultOrder": 2,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 16,
    "name": "ml.t3.xlarge",
    "vcpuNum": 4
   },
   {
    "_defaultOrder": 3,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 32,
    "name": "ml.t3.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 4,
    "_isFastLaunch": true,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 8,
    "name": "ml.m5.large",
    "vcpuNum": 2
   },
   {
    "_defaultOrder": 5,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 16,
    "name": "ml.m5.xlarge",
    "vcpuNum": 4
   },
   {
    "_defaultOrder": 6,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 32,
    "name": "ml.m5.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 7,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 64,
    "name": "ml.m5.4xlarge",
    "vcpuNum": 16
   },
   {
    "_defaultOrder": 8,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 128,
    "name": "ml.m5.8xlarge",
    "vcpuNum": 32
   },
   {
    "_defaultOrder": 9,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 192,
    "name": "ml.m5.12xlarge",
    "vcpuNum": 48
   },
   {
    "_defaultOrder": 10,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 256,
    "name": "ml.m5.16xlarge",
    "vcpuNum": 64
   },
   {
    "_defaultOrder": 11,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 384,
    "name": "ml.m5.24xlarge",
    "vcpuNum": 96
   },
   {
    "_defaultOrder": 12,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 8,
    "name": "ml.m5d.large",
    "vcpuNum": 2
   },
   {
    "_defaultOrder": 13,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 16,
    "name": "ml.m5d.xlarge",
    "vcpuNum": 4
   },
   {
    "_defaultOrder": 14,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 32,
    "name": "ml.m5d.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 15,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 64,
    "name": "ml.m5d.4xlarge",
    "vcpuNum": 16
   },
   {
    "_defaultOrder": 16,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 128,
    "name": "ml.m5d.8xlarge",
    "vcpuNum": 32
   },
   {
    "_defaultOrder": 17,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 192,
    "name": "ml.m5d.12xlarge",
    "vcpuNum": 48
   },
   {
    "_defaultOrder": 18,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 256,
    "name": "ml.m5d.16xlarge",
    "vcpuNum": 64
   },
   {
    "_defaultOrder": 19,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 384,
    "name": "ml.m5d.24xlarge",
    "vcpuNum": 96
   },
   {
    "_defaultOrder": 20,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": true,
    "memoryGiB": 0,
    "name": "ml.geospatial.interactive",
    "supportedImageNames": [
     "sagemaker-geospatial-v1-0"
    ],
    "vcpuNum": 0
   },
   {
    "_defaultOrder": 21,
    "_isFastLaunch": true,
    "category": "Compute optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 4,
    "name": "ml.c5.large",
    "vcpuNum": 2
   },
   {
    "_defaultOrder": 22,
    "_isFastLaunch": false,
    "category": "Compute optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 8,
    "name": "ml.c5.xlarge",
    "vcpuNum": 4
   },
   {
    "_defaultOrder": 23,
    "_isFastLaunch": false,
    "category": "Compute optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 16,
    "name": "ml.c5.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 24,
    "_isFastLaunch": false,
    "category": "Compute optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 32,
    "name": "ml.c5.4xlarge",
    "vcpuNum": 16
   },
   {
    "_defaultOrder": 25,
    "_isFastLaunch": false,
    "category": "Compute optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 72,
    "name": "ml.c5.9xlarge",
    "vcpuNum": 36
   },
   {
    "_defaultOrder": 26,
    "_isFastLaunch": false,
    "category": "Compute optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 96,
    "name": "ml.c5.12xlarge",
    "vcpuNum": 48
   },
   {
    "_defaultOrder": 27,
    "_isFastLaunch": false,
    "category": "Compute optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 144,
    "name": "ml.c5.18xlarge",
    "vcpuNum": 72
   },
   {
    "_defaultOrder": 28,
    "_isFastLaunch": false,
    "category": "Compute optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 192,
    "name": "ml.c5.24xlarge",
    "vcpuNum": 96
   },
   {
    "_defaultOrder": 29,
    "_isFastLaunch": true,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 16,
    "name": "ml.g4dn.xlarge",
    "vcpuNum": 4
   },
   {
    "_defaultOrder": 30,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 32,
    "name": "ml.g4dn.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 31,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 64,
    "name": "ml.g4dn.4xlarge",
    "vcpuNum": 16
   },
   {
    "_defaultOrder": 32,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 128,
    "name": "ml.g4dn.8xlarge",
    "vcpuNum": 32
   },
   {
    "_defaultOrder": 33,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 4,
    "hideHardwareSpecs": false,
    "memoryGiB": 192,
    "name": "ml.g4dn.12xlarge",
    "vcpuNum": 48
   },
   {
    "_defaultOrder": 34,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 256,
    "name": "ml.g4dn.16xlarge",
    "vcpuNum": 64
   },
   {
    "_defaultOrder": 35,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 61,
    "name": "ml.p3.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 36,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 4,
    "hideHardwareSpecs": false,
    "memoryGiB": 244,
    "name": "ml.p3.8xlarge",
    "vcpuNum": 32
   },
   {
    "_defaultOrder": 37,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 8,
    "hideHardwareSpecs": false,
    "memoryGiB": 488,
    "name": "ml.p3.16xlarge",
    "vcpuNum": 64
   },
   {
    "_defaultOrder": 38,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 8,
    "hideHardwareSpecs": false,
    "memoryGiB": 768,
    "name": "ml.p3dn.24xlarge",
    "vcpuNum": 96
   },
   {
    "_defaultOrder": 39,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 16,
    "name": "ml.r5.large",
    "vcpuNum": 2
   },
   {
    "_defaultOrder": 40,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 32,
    "name": "ml.r5.xlarge",
    "vcpuNum": 4
   },
   {
    "_defaultOrder": 41,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 64,
    "name": "ml.r5.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 42,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 128,
    "name": "ml.r5.4xlarge",
    "vcpuNum": 16
   },
   {
    "_defaultOrder": 43,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 256,
    "name": "ml.r5.8xlarge",
    "vcpuNum": 32
   },
   {
    "_defaultOrder": 44,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 384,
    "name": "ml.r5.12xlarge",
    "vcpuNum": 48
   },
   {
    "_defaultOrder": 45,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 512,
    "name": "ml.r5.16xlarge",
    "vcpuNum": 64
   },
   {
    "_defaultOrder": 46,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 768,
    "name": "ml.r5.24xlarge",
    "vcpuNum": 96
   },
   {
    "_defaultOrder": 47,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 16,
    "name": "ml.g5.xlarge",
    "vcpuNum": 4
   },
   {
    "_defaultOrder": 48,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 32,
    "name": "ml.g5.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 49,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 64,
    "name": "ml.g5.4xlarge",
    "vcpuNum": 16
   },
   {
    "_defaultOrder": 50,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 128,
    "name": "ml.g5.8xlarge",
    "vcpuNum": 32
   },
   {
    "_defaultOrder": 51,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 256,
    "name": "ml.g5.16xlarge",
    "vcpuNum": 64
   },
   {
    "_defaultOrder": 52,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 4,
    "hideHardwareSpecs": false,
    "memoryGiB": 192,
    "name": "ml.g5.12xlarge",
    "vcpuNum": 48
   },
   {
    "_defaultOrder": 53,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 4,
    "hideHardwareSpecs": false,
    "memoryGiB": 384,
    "name": "ml.g5.24xlarge",
    "vcpuNum": 96
   },
   {
    "_defaultOrder": 54,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 8,
    "hideHardwareSpecs": false,
    "memoryGiB": 768,
    "name": "ml.g5.48xlarge",
    "vcpuNum": 192
   },
   {
    "_defaultOrder": 55,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 8,
    "hideHardwareSpecs": false,
    "memoryGiB": 1152,
    "name": "ml.p4d.24xlarge",
    "vcpuNum": 96
   },
   {
    "_defaultOrder": 56,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 8,
    "hideHardwareSpecs": false,
    "memoryGiB": 1152,
    "name": "ml.p4de.24xlarge",
    "vcpuNum": 96
   },
   {
    "_defaultOrder": 57,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 32,
    "name": "ml.trn1.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 58,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 512,
    "name": "ml.trn1.32xlarge",
    "vcpuNum": 128
   },
   {
    "_defaultOrder": 59,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 512,
    "name": "ml.trn1n.32xlarge",
    "vcpuNum": 128
   }
  ],
  "instance_type": "ml.t3.medium",
  "kernelspec": {
   "display_name": "Python 3 (Data Science 3.0)",
   "language": "python",
   "name": "python3__SAGEMAKER_INTERNAL__arn:aws:sagemaker:us-east-1:081325390199:image/sagemaker-data-science-310-v1"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
